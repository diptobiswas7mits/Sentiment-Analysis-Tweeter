{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import tokenizers\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.autonotebook import tqdm\n",
    "#import utils\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WD changed from 0.001 to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    EXPERIMENT_NAME = \"exp13\"\n",
    "    MAX_LEN = 192\n",
    "    TRAIN_BATCH_SIZE = 16\n",
    "    VALID_BATCH_SIZE = 8\n",
    "    #GRAD_ACC_STEPS = 2\n",
    "    EPOCHS = 3 # 5 was useless, earlystopping kicked in\n",
    "    LEARNING_RATE = 3e-5\n",
    "    DATA_DIR = Path('')\n",
    "    MODEL_NAME = \"roberta-base\"\n",
    "    TRAINING_FILE = \"train_folds_v2.csv\"\n",
    "    TOKENIZER = tokenizers.ByteLevelBPETokenizer( ##explore this\n",
    "        vocab_file=f\"vocab.json\", \n",
    "        merges_file=f\"merges.txt\", \n",
    "        lowercase=True,\n",
    "        add_prefix_space=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class TweetModel(transformers.BertPreTrainedModel):\n",
    "    def __init__(self, conf):\n",
    "        super(TweetModel, self).__init__(conf)\n",
    "        self.roberta = transformers.RobertaModel.from_pretrained(config.MODEL_NAME, config=conf)\n",
    "        self.drop_out = nn.Dropout(0.3)\n",
    "        self.conv1d_128_0 = nn.Conv1d(768, 128, kernel_size=2, \\\n",
    "                           stride=1, padding=0, dilation=1, groups=1, \\\n",
    "                           bias=True, padding_mode='zeros')\n",
    "        self.conv1d_128_1 = nn.Conv1d(768, 128, kernel_size=2, \\\n",
    "                           stride=1, padding=0, dilation=1, groups=1, \\\n",
    "                           bias=True, padding_mode='zeros')\n",
    "        self.conv1d_64_0 = nn.Conv1d(128, 64, kernel_size=2, \\\n",
    "                           stride=1, padding=0, dilation=1, groups=1, \\\n",
    "                           bias=True, padding_mode='zeros')\n",
    "        self.conv1d_64_1 = nn.Conv1d(128, 64, kernel_size=2, \\\n",
    "                           stride=1, padding=0, dilation=1, groups=1, \\\n",
    "                           bias=True, padding_mode='zeros')\n",
    "        \n",
    "        self.relu = nn.LeakyReLU()\n",
    "        \n",
    "        self.l0 = nn.Linear(64, 1)\n",
    "        self.l1 = nn.Linear(64, 1)\n",
    "        torch.nn.init.normal_(self.l0.weight, std=0.02)\n",
    "        torch.nn.init.normal_(self.l1.weight, std=0.02)\n",
    "        \n",
    "        self.pad = nn.ConstantPad1d((0, 1), 0)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        out, _ = self.roberta( #\n",
    "            ids,\n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        #out =  torch.cat((out[-1], out[-2]), dim=-1)\n",
    "        out1 = out.permute(0, 2, 1)\n",
    "        out1 = self.drop_out(out1)\n",
    "        #print(out.shape)\n",
    "        out1 = self.pad(out1)\n",
    "        #print(out.shape)\n",
    "        out1 = self.conv1d_128_0(out1)\n",
    "        #print(out.shape)\n",
    "        out1 = self.relu(out1)\n",
    "        #print(out.shape)\n",
    "        out1 = self.pad(out1)\n",
    "        out1 = self.conv1d_64_0(out1)\n",
    "        #print(out.shape)\n",
    "        #out = out.flatten()\n",
    "        out1 = out1.permute(0, 2, 1)\n",
    "        #print(out.shape)\n",
    "        start_logits = self.l0(out1)\n",
    "        #print(logits.shape)\n",
    "        \n",
    "        #out =  torch.cat((out[-1], out[-2]), dim=-1)\n",
    "        out2 = out.permute(0, 2, 1)\n",
    "        out2 = self.drop_out(out2)\n",
    "        #print(out.shape)\n",
    "        out2 = self.pad(out2)\n",
    "        #print(out.shape)\n",
    "        out2 = self.conv1d_128_1(out2)\n",
    "        #print(out.shape)\n",
    "        out2 = self.relu(out2)\n",
    "        #print(out.shape)\n",
    "        out2 = self.pad(out2)\n",
    "        out2 = self.conv1d_64_1(out2)\n",
    "        #print(out.shape)\n",
    "        #out = out.flatten()\n",
    "        out2 = out2.permute(0, 2, 1)\n",
    "        #print(out.shape)\n",
    "        end_logits = self.l1(out2)\n",
    "        #print(logits.shape)\n",
    "        \n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def process_data(tweet, selected_text, sentiment, tokenizer, max_len):\n",
    "#     len_st = len(selected_text)\n",
    "#     idx0 = None\n",
    "#     idx1 = None\n",
    "#     for ind in (i for i, e in enumerate(tweet) if e == selected_text[0]):\n",
    "#         if tweet[ind: ind+len_st] == selected_text:\n",
    "#             idx0 = ind\n",
    "#             idx1 = ind + len_st - 1\n",
    "#             break\n",
    "\n",
    "#     char_targets = [0] * len(tweet)\n",
    "#     if idx0 != None and idx1 != None:\n",
    "#         for ct in range(idx0, idx1 + 1):\n",
    "#             char_targets[ct] = 1\n",
    "    \n",
    "#     tok_tweet = tokenizer.encode(tweet)\n",
    "#     input_ids_orig = tok_tweet.ids[1:-1]\n",
    "#     tweet_offsets = tok_tweet.offsets[1:-1]\n",
    "    \n",
    "#     target_idx = []\n",
    "#     for j, (offset1, offset2) in enumerate(tweet_offsets):\n",
    "#         if sum(char_targets[offset1: offset2]) > 0:\n",
    "#             target_idx.append(j)\n",
    "    \n",
    "#     targets_start = target_idx[0]\n",
    "#     targets_end = target_idx[-1]\n",
    "\n",
    "#     sentiment_id = {\n",
    "#         'positive': 3893,\n",
    "#         'negative': 4997,\n",
    "#         'neutral': 8699\n",
    "#     }\n",
    "    \n",
    "#     input_ids = [101] + [sentiment_id[sentiment]] + [102] + input_ids_orig + [102]\n",
    "#     token_type_ids = [0, 0, 0] + [1] * (len(input_ids_orig) + 1)\n",
    "#     mask = [1] * len(token_type_ids)\n",
    "#     tweet_offsets = [(0, 0)] * 3 + tweet_offsets + [(0, 0)]\n",
    "#     targets_start += 3\n",
    "#     targets_end += 3\n",
    "\n",
    "#     padding_length = max_len - len(input_ids)\n",
    "#     if padding_length > 0:\n",
    "#         input_ids = input_ids + ([0] * padding_length)\n",
    "#         mask = mask + ([0] * padding_length)\n",
    "#         token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "#         tweet_offsets = tweet_offsets + ([(0, 0)] * padding_length)\n",
    "    \n",
    "#     return {\n",
    "#         'ids': input_ids,\n",
    "#         'mask': mask,\n",
    "#         'token_type_ids': token_type_ids,\n",
    "#         'targets_start': targets_start,\n",
    "#         'targets_end': targets_end,\n",
    "#         'orig_tweet': tweet,\n",
    "#         'orig_selected': selected_text,\n",
    "#         'sentiment': sentiment,\n",
    "#         'offsets': tweet_offsets\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def process_data(tweet, selected_text, sentiment, tokenizer, max_len):\n",
    "    tweet = \" \" + \" \".join(str(tweet).split())\n",
    "    selected_text = \" \" + \" \".join(str(selected_text).split())\n",
    "\n",
    "    len_st = len(selected_text) - 1\n",
    "    idx0 = None\n",
    "    idx1 = None\n",
    "\n",
    "    for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n",
    "        if \" \" + tweet[ind: ind+len_st] == selected_text:\n",
    "            idx0 = ind\n",
    "            idx1 = ind + len_st - 1\n",
    "            break\n",
    "\n",
    "    char_targets = [0] * len(tweet)\n",
    "    if idx0 != None and idx1 != None:\n",
    "        for ct in range(idx0, idx1 + 1):\n",
    "            char_targets[ct] = 1\n",
    "    \n",
    "    tok_tweet = tokenizer.encode(tweet)\n",
    "    input_ids_orig = tok_tweet.ids\n",
    "    tweet_offsets = tok_tweet.offsets\n",
    "    \n",
    "    target_idx = []\n",
    "    for j, (offset1, offset2) in enumerate(tweet_offsets):\n",
    "        if sum(char_targets[offset1: offset2]) > 0:\n",
    "            target_idx.append(j)\n",
    "    \n",
    "    targets_start = target_idx[0]\n",
    "    targets_end = target_idx[-1]\n",
    "\n",
    "    sentiment_id = {\n",
    "        'positive': 1313,\n",
    "        'negative': 2430,\n",
    "        'neutral': 7974\n",
    "    }\n",
    "    \n",
    "    input_ids = [0] + [sentiment_id[sentiment]] + [2] + [2] + input_ids_orig + [2]\n",
    "    token_type_ids = [0, 0, 0, 0] + [0] * (len(input_ids_orig) + 1)\n",
    "    mask = [1] * len(token_type_ids)\n",
    "    tweet_offsets = [(0, 0)] * 4 + tweet_offsets + [(0, 0)]\n",
    "    targets_start += 4\n",
    "    targets_end += 4\n",
    "\n",
    "    padding_length = max_len - len(input_ids)\n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + ([1] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        tweet_offsets = tweet_offsets + ([(0, 0)] * padding_length)\n",
    "    \n",
    "    return {\n",
    "        'ids': input_ids,\n",
    "        'mask': mask,\n",
    "        'token_type_ids': token_type_ids,\n",
    "        'targets_start': targets_start,\n",
    "        'targets_end': targets_end,\n",
    "        'orig_tweet': tweet,\n",
    "        'orig_selected': selected_text,\n",
    "        'sentiment': sentiment,\n",
    "        'offsets': tweet_offsets\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset:\n",
    "    def __init__(self, tweet, sentiment, selected_text):\n",
    "        self.tweet = tweet\n",
    "        self.sentiment = sentiment\n",
    "        self.selected_text = selected_text\n",
    "        self.tokenizer = config.TOKENIZER\n",
    "        self.max_len = config.MAX_LEN\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tweet)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = process_data(\n",
    "            self.tweet[item], \n",
    "            self.selected_text[item], \n",
    "            self.sentiment[item],\n",
    "            self.tokenizer,\n",
    "            self.max_len\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(data[\"ids\"], dtype=torch.long),\n",
    "            'mask': torch.tensor(data[\"mask\"], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(data[\"token_type_ids\"], dtype=torch.long),\n",
    "            'targets_start': torch.tensor(data[\"targets_start\"], dtype=torch.long),\n",
    "            'targets_end': torch.tensor(data[\"targets_end\"], dtype=torch.long),\n",
    "            'orig_tweet': data[\"orig_tweet\"],\n",
    "            'orig_selected': data[\"orig_selected\"],\n",
    "            'sentiment': data[\"sentiment\"],\n",
    "            'offsets': torch.tensor(data[\"offsets\"], dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def calculate_jaccard_score(\n",
    "    original_tweet, \n",
    "    target_string, \n",
    "    sentiment_val, \n",
    "    idx_start, \n",
    "    idx_end, \n",
    "    offsets,\n",
    "    verbose=False):\n",
    "    \n",
    "    if idx_end < idx_start:\n",
    "        idx_end = idx_start\n",
    "    \n",
    "    filtered_output  = \"\"\n",
    "    for ix in range(idx_start, idx_end + 1):\n",
    "        filtered_output += original_tweet[offsets[ix][0]: offsets[ix][1]]\n",
    "        if (ix+1) < len(offsets) and offsets[ix][1] < offsets[ix+1][0]:\n",
    "            filtered_output += \" \"\n",
    "\n",
    "    if sentiment_val == \"neutral\" or len(original_tweet.split()) < 2:\n",
    "        filtered_output = original_tweet\n",
    "\n",
    "    jac = jaccard(target_string.strip(), filtered_output.strip())\n",
    "    return jac, filtered_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def calculate_jaccard_score(\n",
    "#     original_tweet, \n",
    "#     target_string, \n",
    "#     sentiment_val, \n",
    "#     idx_start, \n",
    "#     idx_end, \n",
    "#     offsets,\n",
    "#     verbose=False):\n",
    "    \n",
    "#     if idx_end < idx_start:\n",
    "#         idx_end = idx_start\n",
    "    \n",
    "#     filtered_output  = \"\"\n",
    "#     for ix in range(idx_start, idx_end + 1):\n",
    "#         filtered_output += original_tweet[offsets[ix][0]: offsets[ix][1]]\n",
    "#         if (ix+1) < len(offsets) and offsets[ix][1] < offsets[ix+1][0]:\n",
    "#             filtered_output += \" \"\n",
    "\n",
    "#     if sentiment_val == \"neutral\" or len(original_tweet.split()) < 2:\n",
    "#         filtered_output = original_tweet\n",
    "\n",
    "#     jac = utils.jaccard(target_string.strip(), filtered_output.strip())\n",
    "#     return jac, filtered_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, mode=\"max\", delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        if self.mode == \"min\":\n",
    "            self.val_score = np.Inf\n",
    "        else:\n",
    "            self.val_score = -np.Inf\n",
    "\n",
    "    def __call__(self, epoch_score, model, model_path):\n",
    "\n",
    "        if self.mode == \"min\":\n",
    "            score = -1.0 * epoch_score\n",
    "        else:\n",
    "            score = np.copy(epoch_score)\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, epoch_score, model, model_path):\n",
    "        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n",
    "            print('Validation score improved ({} --> {}). Saving model!'.format(self.val_score, epoch_score))\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        self.val_score = epoch_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def eval_fn(data_loader, model, device):\n",
    "#     model.eval()\n",
    "#     losses = utils.AverageMeter()\n",
    "#     jaccards = utils.AverageMeter()\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "#         for bi, d in enumerate(tk0):\n",
    "#             ids = d[\"ids\"]\n",
    "#             token_type_ids = d[\"token_type_ids\"]\n",
    "#             mask = d[\"mask\"]\n",
    "#             sentiment = d[\"sentiment\"]\n",
    "#             orig_selected = d[\"orig_selected\"]\n",
    "#             orig_tweet = d[\"orig_tweet\"]\n",
    "#             targets_start = d[\"targets_start\"]\n",
    "#             targets_end = d[\"targets_end\"]\n",
    "#             offsets = d[\"offsets\"].numpy()\n",
    "\n",
    "#             ids = ids.to(device, dtype=torch.long)\n",
    "#             token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "#             mask = mask.to(device, dtype=torch.long)\n",
    "#             targets_start = targets_start.to(device, dtype=torch.long)\n",
    "#             targets_end = targets_end.to(device, dtype=torch.long)\n",
    "\n",
    "#             outputs_start, outputs_end = model(\n",
    "#                 ids=ids,\n",
    "#                 mask=mask,\n",
    "#                 token_type_ids=token_type_ids\n",
    "#             )\n",
    "#             loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n",
    "#             outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "#             outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "#             jaccard_scores = []\n",
    "#             for px, tweet in enumerate(orig_tweet):\n",
    "#                 selected_tweet = orig_selected[px]\n",
    "#                 tweet_sentiment = sentiment[px]\n",
    "#                 jaccard_score, _ = calculate_jaccard_score(\n",
    "#                     original_tweet=tweet,\n",
    "#                     target_string=selected_tweet,\n",
    "#                     sentiment_val=tweet_sentiment,\n",
    "#                     idx_start=np.argmax(outputs_start[px, :]),\n",
    "#                     idx_end=np.argmax(outputs_end[px, :]),\n",
    "#                     offsets=offsets[px]\n",
    "#                 )\n",
    "#                 jaccard_scores.append(jaccard_score)\n",
    "\n",
    "#             jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
    "#             losses.update(loss.item(), ids.size(0))\n",
    "#             tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)\n",
    "    \n",
    "#     print(f\"Jaccard = {jaccards.avg}\")\n",
    "#     return jaccards.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(start_logits, end_logits, start_positions, end_positions):\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    start_loss = loss_fct(start_logits, start_positions)\n",
    "    end_loss = loss_fct(end_logits, end_positions)\n",
    "    total_loss = (start_loss + end_loss)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(data_loader, model, optimizer, device, scheduler=None):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    jaccards = AverageMeter()\n",
    "\n",
    "    tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "    \n",
    "    for bi, d in enumerate(tk0):\n",
    "\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        sentiment = d[\"sentiment\"]\n",
    "        orig_selected = d[\"orig_selected\"]\n",
    "        orig_tweet = d[\"orig_tweet\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        offsets = d[\"offsets\"]\n",
    "        \n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets_start = targets_start.to(device, dtype=torch.long)\n",
    "        targets_end = targets_end.to(device, dtype=torch.long)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        outputs_start, outputs_end = model(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        ) \n",
    "        loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "        \n",
    "        jaccard_scores = []\n",
    "        for px, tweet in enumerate(orig_tweet):\n",
    "            selected_tweet = orig_selected[px]\n",
    "            tweet_sentiment = sentiment[px]\n",
    "            jaccard_score, _ = calculate_jaccard_score(\n",
    "                original_tweet=tweet, # Full text of the px'th tweet in the batch\n",
    "                target_string=selected_tweet, # Span containing the specified sentiment for the px'th tweet in the batch\n",
    "                sentiment_val=tweet_sentiment, # Sentiment of the px'th tweet in the batch\n",
    "                idx_start=np.argmax(outputs_start[px, :]), # Predicted start index for the px'th tweet in the batch\n",
    "                idx_end=np.argmax(outputs_end[px, :]), # Predicted end index for the px'th tweet in the batch\n",
    "                offsets=offsets[px] # Offsets for each of the tokens for the px'th tweet in the batch\n",
    "            )\n",
    "            jaccard_scores.append(jaccard_score)\n",
    "\n",
    "        jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
    "        losses.update(loss.item(), ids.size(0))\n",
    "        tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def eval_fn(data_loader, model, device):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    jaccards = AverageMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "        for bi, d in enumerate(tk0):\n",
    "            ids = d[\"ids\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            sentiment = d[\"sentiment\"]\n",
    "            orig_selected = d[\"orig_selected\"]\n",
    "            orig_tweet = d[\"orig_tweet\"]\n",
    "            targets_start = d[\"targets_start\"]\n",
    "            targets_end = d[\"targets_end\"]\n",
    "            offsets = d[\"offsets\"].numpy()\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets_start = targets_start.to(device, dtype=torch.long)\n",
    "            targets_end = targets_end.to(device, dtype=torch.long)\n",
    "\n",
    "            outputs_start, outputs_end = model(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "            loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n",
    "            outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "            outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "            jaccard_scores = []\n",
    "            for px, tweet in enumerate(orig_tweet):\n",
    "                selected_tweet = orig_selected[px]\n",
    "                tweet_sentiment = sentiment[px]\n",
    "                jaccard_score, _ = calculate_jaccard_score(\n",
    "                    original_tweet=tweet,\n",
    "                    target_string=selected_tweet,\n",
    "                    sentiment_val=tweet_sentiment,\n",
    "                    idx_start=np.argmax(outputs_start[px, :]),\n",
    "                    idx_end=np.argmax(outputs_end[px, :]),\n",
    "                    offsets=offsets[px]\n",
    "                )\n",
    "                jaccard_scores.append(jaccard_score)\n",
    "\n",
    "            jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
    "            losses.update(loss.item(), ids.size(0))\n",
    "            tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)\n",
    "    \n",
    "    print(f\"Jaccard = {jaccards.avg}\")\n",
    "    return jaccards.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fold):\n",
    "    dfx = pd.read_csv(config.TRAINING_FILE)\n",
    "\n",
    "    df_train = dfx[dfx.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = dfx[dfx.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = TweetDataset(\n",
    "        tweet=df_train.text.values,\n",
    "        sentiment=df_train.sentiment.values,\n",
    "        selected_text=df_train.selected_text.values\n",
    "    )\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.TRAIN_BATCH_SIZE,\n",
    "        num_workers=4\n",
    "        #shuffle=True\n",
    "    )\n",
    "\n",
    "    valid_dataset = TweetDataset(\n",
    "        tweet=df_valid.text.values,\n",
    "        sentiment=df_valid.sentiment.values,\n",
    "        selected_text=df_valid.selected_text.values\n",
    "    )\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=config.VALID_BATCH_SIZE,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    model_config = transformers.RobertaConfig.from_pretrained(config.MODEL_NAME)\n",
    "    #model_config.output_hidden_states = True\n",
    "    model = TweetModel(conf=model_config)\n",
    "    model.to(device)\n",
    "\n",
    "    num_train_steps = int(len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.1},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_parameters, lr=config.LEARNING_RATE)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=0, \n",
    "        num_training_steps=num_train_steps\n",
    "    )\n",
    "\n",
    "    es = EarlyStopping(patience=2, mode=\"max\")\n",
    "    print(f\"Training is Starting for fold={fold}\")\n",
    "    \n",
    "    for epoch in range(config.EPOCHS):\n",
    "        train_fn(train_data_loader, model, optimizer, device, scheduler=scheduler)\n",
    "        jaccard = eval_fn(valid_data_loader, model, device)\n",
    "        print(f\"Jaccard Score = {jaccard}\")\n",
    "        es(jaccard, model, model_path=f\"model_{fold}-{config.EXPERIMENT_NAME}.bin\")\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is Starting for fold=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a140589cc3fc40268084d22effa9213b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89dca3a517334ba5b371973465f38799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.6995273798467261\n",
      "Jaccard Score = 0.6995273798467261\n",
      "Validation score improved (-inf --> 0.6995273798467261). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d26b47e0494cc09cfc2781fe872bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad25d0886f334cf1be3e5665b36ebf73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.7044061230382251\n",
      "Jaccard Score = 0.7044061230382251\n",
      "Validation score improved (0.6995273798467261 --> 0.7044061230382251). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44559e284014bfa966ea53c53aba8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fad8daa1f344255a4d6301cf976e45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.7072078847741243\n",
      "Jaccard Score = 0.7072078847741243\n",
      "Validation score improved (0.7044061230382251 --> 0.7072078847741243). Saving model!\n"
     ]
    }
   ],
   "source": [
    "run(fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is Starting for fold=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4faf7a8dc25140f49a1304d6ee57136e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b022c913e0246dca04e9faebce7a87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.6932219399327164\n",
      "Jaccard Score = 0.6932219399327164\n",
      "Validation score improved (-inf --> 0.6932219399327164). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4be5fd58774ecd9fc7f1dd1daa3261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c038fd0ededc49a0aa0afb842fa9d116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.7053246698049863\n",
      "Jaccard Score = 0.7053246698049863\n",
      "Validation score improved (0.6932219399327164 --> 0.7053246698049863). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff5e74ca79e47bd95a2aa3f8c8f148b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad145a9ca044e2b85f69f77a65451aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.7082901640737208\n",
      "Jaccard Score = 0.7082901640737208\n",
      "Validation score improved (0.7053246698049863 --> 0.7082901640737208). Saving model!\n"
     ]
    }
   ],
   "source": [
    "run(fold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is Starting for fold=2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf2449b65714481be4d87fa00f8e508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9e5a88d98244098ea659709e1ea9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.6918292011892714\n",
      "Jaccard Score = 0.6918292011892714\n",
      "Validation score improved (-inf --> 0.6918292011892714). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf6b3c1fc2040de8bcd2bcf70a53af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188bacae4ce6448aaf4540eed6c3c632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.7005601814064034\n",
      "Jaccard Score = 0.7005601814064034\n",
      "Validation score improved (0.6918292011892714 --> 0.7005601814064034). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa41d03a8d924e779b66cdac7b4b59cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d631e92d0e9b4a13983a5770ef934f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.7046130158404055\n",
      "Jaccard Score = 0.7046130158404055\n",
      "Validation score improved (0.7005601814064034 --> 0.7046130158404055). Saving model!\n"
     ]
    }
   ],
   "source": [
    "run(fold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is Starting for fold=3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f4b2384ca84ce593cae068c87bc2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7c89d4dda54842b6d3446795bc4eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.7048642068884446\n",
      "Jaccard Score = 0.7048642068884446\n",
      "Validation score improved (-inf --> 0.7048642068884446). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ace08380d249bd9222832f96c630b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3681eab6ee9c41da88beb6ff050fb904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.7113274487851486\n",
      "Jaccard Score = 0.7113274487851486\n",
      "Validation score improved (0.7048642068884446 --> 0.7113274487851486). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f880228e074349c4bf6f29db081f38ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85617ef909884ea683798bad99ae473d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.7113701501526515\n",
      "Jaccard Score = 0.7113701501526515\n",
      "EarlyStopping counter: 1 out of 2\n"
     ]
    }
   ],
   "source": [
    "run(fold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is Starting for fold=4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e53153863d46ea8fc245df5ac4a51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d3df6310ac49d0a5b4c8747ed5bff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.7051730898938482\n",
      "Jaccard Score = 0.7051730898938482\n",
      "Validation score improved (-inf --> 0.7051730898938482). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd741cac325b465085f5e79d8a895a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5250f83f5b824fe381f933c78234d98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.7088611114679174\n",
      "Jaccard Score = 0.7088611114679174\n",
      "Validation score improved (0.7051730898938482 --> 0.7088611114679174). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12fbe8da5d84147a9360bb37a4fd092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b2fd77949d4221bf8d83bfdf1f1d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.7117904850205493\n",
      "Jaccard Score = 0.7117904850205493\n",
      "Validation score improved (0.7088611114679174 --> 0.7117904850205493). Saving model!\n"
     ]
    }
   ],
   "source": [
    "run(fold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7086"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.7072 + 0.7082 + 0.7046 + 0.7113 + 0.7117)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_test.loc[:, \"selected_text\"] = df_test.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model_config = transformers.RobertaConfig.from_pretrained(config.MODEL_NAME)\n",
    "######## ????\n",
    "#model_config.output_hidden_states = True\n",
    "######## ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TweetModel(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (drop_out): Dropout(p=0.3, inplace=False)\n",
       "  (conv1d_128_0): Conv1d(768, 128, kernel_size=(2,), stride=(1,))\n",
       "  (conv1d_128_1): Conv1d(768, 128, kernel_size=(2,), stride=(1,))\n",
       "  (conv1d_64_0): Conv1d(128, 64, kernel_size=(2,), stride=(1,))\n",
       "  (conv1d_64_1): Conv1d(128, 64, kernel_size=(2,), stride=(1,))\n",
       "  (relu): LeakyReLU(negative_slope=0.01)\n",
       "  (l0): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (l1): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (pad): ConstantPad1d(padding=(0, 1), value=0)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = TweetModel(conf=model_config)\n",
    "model1.to(device)\n",
    "model1.load_state_dict(torch.load(f\"model_0-{config.EXPERIMENT_NAME}.bin\"))\n",
    "model1.eval()\n",
    "\n",
    "model2 = TweetModel(conf=model_config)\n",
    "model2.to(device)\n",
    "model2.load_state_dict(torch.load(f\"model_1-{config.EXPERIMENT_NAME}.bin\"))\n",
    "model2.eval()\n",
    "\n",
    "model3 = TweetModel(conf=model_config)\n",
    "model3.to(device)\n",
    "model3.load_state_dict(torch.load(f\"model_2-{config.EXPERIMENT_NAME}.bin\"))\n",
    "model3.eval()\n",
    "\n",
    "model4 = TweetModel(conf=model_config)\n",
    "model4.to(device)\n",
    "model4.load_state_dict(torch.load(f\"model_3-{config.EXPERIMENT_NAME}.bin\"))\n",
    "model4.eval()\n",
    "\n",
    "model5 = TweetModel(conf=model_config)\n",
    "model5.to(device)\n",
    "model5.load_state_dict(torch.load(f\"model_4-{config.EXPERIMENT_NAME}.bin\"))\n",
    "model5.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TweetDataset(\n",
    "        tweet=df_test.text.values,\n",
    "        sentiment=df_test.sentiment.values,\n",
    "        selected_text=df_test.selected_text.values\n",
    "    )\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=config.VALID_BATCH_SIZE,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbb192a8dc540b5a05fff061964f6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=442.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_output = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "    for bi, d in enumerate(tk0):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        sentiment = d[\"sentiment\"]\n",
    "        orig_selected = d[\"orig_selected\"]\n",
    "        orig_tweet = d[\"orig_tweet\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        offsets = d[\"offsets\"].numpy()\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets_start = targets_start.to(device, dtype=torch.long)\n",
    "        targets_end = targets_end.to(device, dtype=torch.long)\n",
    "\n",
    "        outputs_start1, outputs_end1 = model1(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        outputs_start2, outputs_end2 = model2(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        outputs_start3, outputs_end3 = model3(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        outputs_start4, outputs_end4 = model4(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        outputs_start5, outputs_end5 = model5(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        outputs_start = (outputs_start1 + outputs_start2 + outputs_start3 + outputs_start4 + outputs_start5) / 5\n",
    "        outputs_end = (outputs_end1 + outputs_end2 + outputs_end3 + outputs_end4 + outputs_end5) / 5\n",
    "        \n",
    "#         outputs_start = outputs_start1\n",
    "#         outputs_end = outputs_end1\n",
    "        \n",
    "        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "        jaccard_scores = []\n",
    "        for px, tweet in enumerate(orig_tweet):\n",
    "            selected_tweet = orig_selected[px]\n",
    "            tweet_sentiment = sentiment[px]\n",
    "            _, output_sentence = calculate_jaccard_score(\n",
    "                original_tweet=tweet,\n",
    "                target_string=selected_tweet,\n",
    "                sentiment_val=tweet_sentiment,\n",
    "                idx_start=np.argmax(outputs_start[px, :]),\n",
    "                idx_end=np.argmax(outputs_end[px, :]),\n",
    "                offsets=offsets[px]\n",
    "            )\n",
    "            final_output.append(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"sample_submission.csv\")\n",
    "sample.loc[:, 'selected_text'] = final_output\n",
    "sample.to_csv(f\"submission-{config.EXPERIMENT_NAME}-5fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719e69ef237a498aa7d1a596f3d4c443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=442.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day http://twitpic.com/67ezh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>exciting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>such a shame!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>I like it!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                      selected_text\n",
       "0  f87dea47db   Last session of the day http://twitpic.com/67ezh\n",
       "1  96d74cb729                                           exciting\n",
       "2  eee518ae67                                      such a shame!\n",
       "3  01082688c6                                        happy bday!\n",
       "4  33987a8ee5                                        I like it!!"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "    for bi, d in enumerate(tk0):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        sentiment = d[\"sentiment\"]\n",
    "        orig_selected = d[\"orig_selected\"]\n",
    "        orig_tweet = d[\"orig_tweet\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        offsets = d[\"offsets\"].numpy()\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets_start = targets_start.to(device, dtype=torch.long)\n",
    "        targets_end = targets_end.to(device, dtype=torch.long)\n",
    "\n",
    "        outputs_start, outputs_end = model1(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "        \n",
    "        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "        jaccard_scores = []\n",
    "        for px, tweet in enumerate(orig_tweet):\n",
    "            selected_tweet = orig_selected[px]\n",
    "            tweet_sentiment = sentiment[px]\n",
    "            _, output_sentence = calculate_jaccard_score(\n",
    "                original_tweet=tweet,\n",
    "                target_string=selected_tweet,\n",
    "                sentiment_val=tweet_sentiment,\n",
    "                idx_start=np.argmax(outputs_start[px, :]),\n",
    "                idx_end=np.argmax(outputs_end[px, :]),\n",
    "                offsets=offsets[px]\n",
    "            )\n",
    "            final_output.append(output_sentence)\n",
    "    \n",
    "sample = pd.read_csv(\"sample_submission.csv\")\n",
    "sample.loc[:, 'selected_text'] = final_output\n",
    "sample.to_csv(f\"submission-{config.EXPERIMENT_NAME}-fold1.csv\", index=False)\n",
    "\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
